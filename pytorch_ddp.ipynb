{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0588ae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, random_split, DistributedSampler\n",
    "from torchvision.datasets import MNIST\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import transforms\n",
    "import torch.nn as nn\n",
    "\n",
    "# A pytorch wrapper of multiprocessing\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.distributed import init_process_group, destroy_process_group\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8731514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddp_setup(rank, world_size):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    - rank: unique identifier of each process\n",
    "    - world_size: total number of processes\n",
    "    \"\"\"\n",
    "\n",
    "    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "    os.environ[\"MASTER_PORT\"] = \"12355\"\n",
    "\n",
    "    init_process_group(backend=\"gloo\", rank=rank, world_size=world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc6006d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classic trainer\n",
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: torch.nn.Module,\n",
    "        train_data: DataLoader,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        gpu_id: torch.device,\n",
    "        save_every: int,\n",
    "        rank: int\n",
    "    ):\n",
    "        self.gpu_id = gpu_id\n",
    "        # Modified compared to the GPU version\n",
    "        self.model = DDP(model.to(gpu_id))\n",
    "        self.train_data = train_data\n",
    "        self.optimizer = optimizer\n",
    "        self.save_every = save_every\n",
    "        self.validation_steps = [{\"val_loss: \": 10000.0, \"val_acc\": 0}]\n",
    "        self.rank = rank\n",
    "\n",
    "    \n",
    "    def _run_batch(self, source, targets):\n",
    "        self.optimizer.zero_grad()\n",
    "        output = self.model(source)\n",
    "        loss = torch.nn.CrossEntropyLoss()(output, targets)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def _run_epoch(self, epoch):\n",
    "        # b_sz = len(next(iter(self.train_data)))\n",
    "        for source, targets in self.train_data:\n",
    "            source = source.to(self.gpu_id)\n",
    "            targets = targets.to(self.gpu_id)\n",
    "            \n",
    "            self._run_batch(source, targets)\n",
    "    \n",
    "    def _accuracy(self, outputs, labels):\n",
    "        outputs = outputs.to(self.gpu_id)\n",
    "        labels = labels.to(self.gpu_id)\n",
    "        out = self.model(outputs)\n",
    "        loss = nn.functional.cross_entropy(out, labels)\n",
    "        _, preds = torch.max(out, dim=1)\n",
    "        acc = (torch.tensor(torch.sum(preds == labels).item() / len(preds)))\n",
    "        val = {\"val_loss: \": loss.item(), \"val_acc\": acc.item()}\n",
    "        self.validation_steps.append(val)\n",
    "        print(val)\n",
    "    \n",
    "    def _validation_step(self):\n",
    "        source, targets = next(iter(self.train_data))\n",
    "        self._accuracy(source, targets)\n",
    "        \n",
    "            \n",
    "    def _save_checkpoint(self, epoch):\n",
    "        ckp = self.model.module.state_dict()\n",
    "        torch.save(ckp, \"checkpoint.pt\")\n",
    "        # print(f\"epoch: {epoch}, gpu_id: {self.gpu_id}, val_loss_acc: {self.validation_steps[-1]}\")\n",
    "    \n",
    "    def train(self, max_epochs):\n",
    "        self.model.train()\n",
    "        with torch.profiler.profile(\n",
    "            schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=2),\n",
    "            on_trace_ready=torch.profiler.tensorboard_trace_handler(f'./log/rank_{self.gpu_id}'),\n",
    "            record_shapes=True,\n",
    "            profile_memory=True,\n",
    "            with_stack=True\n",
    "        ) as prof:\n",
    "            for i in range(max_epochs):\n",
    "                print(f\"epoch: {i}, gpu_id: {self.gpu_id}, val_loss_acc: {self.validation_steps[-1]}, rank: {self.rank}\")\n",
    "                self.train_data.sampler.set_epoch(i)\n",
    "                self._run_epoch(i)\n",
    "                self._validation_step()\n",
    "                prof.step()\n",
    "                if (i % self.save_every) == 0:\n",
    "                    self._save_checkpoint(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb782a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset = MNIST(root=\"data/\", train=True, download=True, transform=transforms.ToTensor())\n",
    "train_data, validation_data = random_split(mnist_dataset, [50000, 10000])\n",
    "\n",
    "shape = train_data.dataset.data.shape\n",
    "input_size = shape[-1] * shape[-2]\n",
    "num_classes = len(train_data.dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f4a7a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistModel(nn.Module):\n",
    "    def __init__(self, input_size: int, output_size: int):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4025861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_fn(rank: int, world_size: int, total_epochs: int, save_every: int):\n",
    "    ddp_setup(rank, world_size)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_id = 0\n",
    "    else: \n",
    "        gpu_id = \"cpu\"\n",
    "    model = MnistModel(input_size, num_classes)\n",
    "    train_loader = DataLoader(train_data, batch_size=512, shuffle=False, sampler=DistributedSampler(train_data))\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    trainer = Trainer(model, train_loader, optimizer, gpu_id, save_every, rank)\n",
    "    trainer.train(max_epochs=total_epochs)\n",
    "    destroy_process_group()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08ba7292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, gpu_id: 0, val_loss_acc: {'val_loss: ': 10000.0, 'val_acc': 0}, rank: 0\n",
      "epoch: 0, gpu_id: 0, val_loss_acc: {'val_loss: ': 10000.0, 'val_acc': 0}, rank: 1\n",
      "epoch: 0, gpu_id: 0, val_loss_acc: {'val_loss: ': 10000.0, 'val_acc': 0}, rank: 2\n",
      "{'val_loss: ': 0.9375135898590088, 'val_acc': 0.8203125}\n",
      "{'val_loss: ': 0.9674522280693054, 'val_acc': 0.83203125}\n",
      "{'val_loss: ': 0.9487961530685425, 'val_acc': 0.83984375}\n",
      "epoch: 1, gpu_id: 0, val_loss_acc: {'val_loss: ': 0.9375135898590088, 'val_acc': 0.8203125}, rank: 0\n",
      "epoch: 1, gpu_id: 0, val_loss_acc: {'val_loss: ': 0.9674522280693054, 'val_acc': 0.83203125}, rank: 1\n",
      "epoch: 1, gpu_id: 0, val_loss_acc: {'val_loss: ': 0.9487961530685425, 'val_acc': 0.83984375}, rank: 2\n",
      "{'val_loss: ': 0.7085767388343811, 'val_acc': 0.83984375}\n",
      "epoch: 2, gpu_id: 0, val_loss_acc: {'val_loss: ': 0.7085767388343811, 'val_acc': 0.83984375}, rank: 0\n",
      "{'val_loss: ': 0.6606341004371643, 'val_acc': 0.857421875}\n",
      "epoch: 2, gpu_id: 0, val_loss_acc: {'val_loss: ': 0.6606341004371643, 'val_acc': 0.857421875}, rank: 1\n",
      "{'val_loss: ': 0.6760732531547546, 'val_acc': 0.8515625}\n",
      "epoch: 2, gpu_id: 0, val_loss_acc: {'val_loss: ': 0.6760732531547546, 'val_acc': 0.8515625}, rank: 2\n",
      "{'val_loss: ': 0.5997426509857178, 'val_acc': 0.857421875}\n",
      "epoch: 3, gpu_id: 0, val_loss_acc: {'val_loss: ': 0.5997426509857178, 'val_acc': 0.857421875}, rank: 0\n",
      "{'val_loss: ': 0.5907580256462097, 'val_acc': 0.861328125}\n",
      "epoch: 3, gpu_id: 0, val_loss_acc: {'val_loss: ': 0.5907580256462097, 'val_acc': 0.861328125}, rank: 2\n",
      "{'val_loss: ': 0.5886672139167786, 'val_acc': 0.8671875}\n",
      "epoch: 3, gpu_id: 0, val_loss_acc: {'val_loss: ': 0.5886672139167786, 'val_acc': 0.8671875}, rank: 1\n",
      "{'val_loss: ': 0.5218867659568787, 'val_acc': 0.884765625}\n",
      "epoch: 4, gpu_id: 0, val_loss_acc: {'val_loss: ': 0.5218867659568787, 'val_acc': 0.884765625}, rank: 0\n",
      "{'val_loss: ': 0.6042006015777588, 'val_acc': 0.841796875}\n",
      "epoch: 4, gpu_id: 0, val_loss_acc: {'val_loss: ': 0.6042006015777588, 'val_acc': 0.841796875}, rank: 2\n",
      "{'val_loss: ': 0.552358090877533, 'val_acc': 0.86328125}\n",
      "epoch: 4, gpu_id: 0, val_loss_acc: {'val_loss: ': 0.552358090877533, 'val_acc': 0.86328125}, rank: 1\n",
      "{'val_loss: ': 0.51786208152771, 'val_acc': 0.87890625}\n",
      "{'val_loss: ': 0.5532435774803162, 'val_acc': 0.853515625}\n",
      "{'val_loss: ': 0.5344510674476624, 'val_acc': 0.87109375}\n"
     ]
    }
   ],
   "source": [
    "from pytorch_ddp_gloo import main\n",
    "\n",
    "total_epochs = 5\n",
    "save_every = 5\n",
    "world_size = 3\n",
    "mp.spawn(main, args=(world_size, total_epochs, save_every), nprocs=world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20dbf58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_ddp_intro (3.10.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
